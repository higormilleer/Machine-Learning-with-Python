{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Naive Bayes (the easy way)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We'll cheat by using sklearn.naive_bayes to train a spam classifier! Most of the code is just loading our training data into a pandas DataFrame that we can play with:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os  #serve para manipular caminhos de diretorios e arquivos\nimport io  #lida com fluxos de arquivos\nimport numpy \nimport pandas as pd  \nfrom pandas import DataFrame  \nfrom sklearn.feature_extraction.text import CountVectorizer  #transformar mensagens em valores numéricos\nfrom sklearn.naive_bayes import MultinomialNB  #algoritimo responsavel pelo aprendizado de maquina para classificacao\n\n\ndef readFiles(path):\n    for root, dirnames, filenames in os.walk(path):  #caminha pelos diretorios especificados\n        for filename in filenames:  #itera sobre cada arquivo\n            path = os.path.join(root, filename)  #pega o caminho completo do arquivo\n\n            inBody = False  #identificar se estamos na parte do corpo do e-mail\n            lines = []  #lista para armazenar as linhas do corpo do e-mail\n            f = io.open(path, 'r', encoding='latin1')  # Abre o arquivo \n            for line in f:\n                if inBody:  # caso ja esteja na parte do corpo, adicionamos as linhas\n                    lines.append(line)\n                elif line == '\\n':  # Uma linha em branco separa o cabecalho do corpo\n                    inBody = True\n            f.close()  # Fecha o arquivo\n            message = '\\n'.join(lines)  # Junta as linhas do corpo em uma unica string\n            yield path, message  #retorna o caminho do arquivo e o conteudo do e-mail\n\n\n\ndef dataFrameFromDirectory(path, classification):\n    rows = []  #lista para armazenar os dados de cada arquivo\n    index = []  #lista para armazenar os nomes dos arquivos como indice\n    for filename, message in readFiles(path):  # Usa a função anterior para ler arquivos\n        rows.append({'message': message, 'class': classification})  # Adiciona uma linha com a mensagem e a classe ('spam' ou 'ham')\n        index.append(filename)  # Adiciona o nome do arquivo ao indice anteriormente citado\n        \n\n    return DataFrame(rows, index=index)  # Retorna um DataFrame com os dados\n\n\ndata = DataFrame({'message': [], 'class': []})  # Cria um DataFrame vazio com colunas 'message' e 'class'\n\n#For Pandas 1.3:\ndata = pd.append(data, dataFrameFromDirectory('/Users/heloamillergrassi/Downloads/MLCourse/emails/spam','spam'))\ndata = pd.append(data, dataFrameFromDirectory('/Users/heloamillergrassi/Downloads/MLCourse/emails/ham', 'ham'))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's have a look at that DataFrame:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now we will use a CountVectorizer to split up each message into its list of words, and throw that into a MultinomialNB classifier. Call fit() and we've got a trained spam filter ready to go! It's just that easy.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#basicamnete conta quantas vezes certa palavra apareceu nos emails\n\n#transformar as mensagens em uma matriz numérica\nvectorizer = CountVectorizer()\n\n# 'fit_transform' aprende o vocabulário das mensagens e transforma as mensagens em uma matriz de contagem de palavras\ncounts = vectorizer.fit_transform(data['message'].values)\n\n# Criando o classificador MultinomialNB (Naive Bayes para dados de contagem)\nclassifier = MultinomialNB()\n\n# Definindo as classes (spam ou ham) como o alvo\ntargets = data['class'].values\n\n# Treinando o classificador com as contagens de palavras e os alvos\nclassifier.fit(counts, targets)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's try it out:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#conta as palavras do email posterior, para conseguirmos definir se e spam ou nao\n\n# Novas mensagens de exemplo\nexamples = ['Free Viagra now!!!', \"Hi Bob, how about a game of golf tomorrow?\"]\n\n# Transformando as novas mensagens de email em uma representação numeica\nexample_counts = vectorizer.transform(examples)\n\n# Fazendo a previsao das classes (spam ou ham) para as novas mensagens\npredictions = classifier.predict(example_counts)\n\n# Exibindo as previsoes\nprint(predictions)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Activity",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Our data set is small, so our spam classifier isn't actually very good. Try running some different test emails through it and see if you get the results you expect.\n\nIf you really want to challenge yourself, try applying train/test to this spam classifier - see how well it can predict some subset of the ham and spam emails.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os  #serve para manipular caminhos de diretorios e arquivos\nimport io  #lida com fluxos de arquivos\nimport numpy \nimport pandas as pd  \nfrom pandas import DataFrame  \nfrom sklearn.feature_extraction.text import CountVectorizer  #transformar mensagens em valores numéricos\nfrom sklearn.naive_bayes import MultinomialNB  #algoritimo responsavel pelo aprendizado de maquina para classificacao\n\n\ndef readFiles(path):\n    for root, dirnames, filenames in os.walk(path):  #caminha pelos diretorios especificados\n        for filename in filenames:  #itera sobre cada arquivo\n            path = os.path.join(root, filename)  #pega o caminho completo do arquivo\n\n            inBody = False  #identificar se estamos na parte do corpo do e-mail\n            lines = []  #lista para armazenar as linhas do corpo do e-mail\n            f = io.open(path, 'r', encoding='latin1')  # Abre o arquivo \n            for line in f:\n                if inBody:  # caso ja esteja na parte do corpo, adicionamos as linhas\n                    lines.append(line)\n                elif line == '\\n':  # Uma linha em branco separa o cabecalho do corpo\n                    inBody = True\n            f.close()  # Fecha o arquivo\n            message = '\\n'.join(lines)  # Junta as linhas do corpo em uma unica string\n            yield path, message  #retorna o caminho do arquivo e o conteudo do e-mail\n\n\n\ndef dataFrameFromDirectory(path, classification):\n    rows = []  #lista para armazenar os dados de cada arquivo\n    index = []  #lista para armazenar os nomes dos arquivos como indice\n    for filename, message in readFiles(path):  # Usa a função anterior para ler arquivos\n        rows.append({'message': message, 'class': classification})  # Adiciona uma linha com a mensagem e a classe ('spam' ou 'ham')\n        index.append(filename)  # Adiciona o nome do arquivo ao indice anteriormente citado\n        \n\n    return DataFrame(rows, index=index)  # Retorna um DataFrame com os dados\n\n\ndata = DataFrame({'message': [], 'class': []})  # Cria um DataFrame vazio com colunas 'message' e 'class'\ndata = pd.append(data, dataFrameFromDirectory('/Users/heloamillergrassi/Downloads/MLCourse/emails/spam','spam'))\ndata = pd.append(data, dataFrameFromDirectory('/Users/heloamillergrassi/Downloads/MLCourse/emails/ham', 'ham'))\n\n# Criando o vetor de características a partir das mensagens\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(data['message'].values)  # Transforma as mensagens em uma matriz de contagem de palavras\n\n# Definindo as classes (spam ou ham) como alvo\ny = data['class'].values\n\n# Dividindo os dados em conjunto de treino e conjunto de teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Criando o classificador Multinomial Naive Bayes\nclassifier = MultinomialNB()\n\n# Treinando o classificador com os dados de treino\nclassifier.fit(X_train, y_train)\n\n# Fazendo previsões com os dados de teste\ny_pred = classifier.predict(X_test)\n\n# Avaliando a acurácia do modelo\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f'\\accuracy do modelo: {accuracy:.4f}')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}